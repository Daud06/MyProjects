{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (2.24.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (1.25.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (from bs4) (4.9.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.0.1)\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\programdata\\anaconda3\\lib\\site-packages (3.0.4)\n",
      "Requirement already satisfied: jdcal in c:\\programdata\\anaconda3\\lib\\site-packages (from openpyxl) (1.4.1)\n",
      "Requirement already satisfied: et-xmlfile in c:\\programdata\\anaconda3\\lib\\site-packages (from openpyxl) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_fortune = \"https://www.caifuzhongwen.com/fortune500/paiming/china500/2019_%e4%b8%ad%e5%9b%bd500%e5%bc%ba.htm\"\n",
    "url_base = \"https://www.caifuzhongwen.com/fortune500/gongsi/china500/2024/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook, load_workbook\n",
    "workbook = Workbook()\n",
    "sheet = workbook.active  # Получаем активный лист"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet[f'A1'] = \"Country\"\n",
    "sheet[f'B1'] = \"City\"\n",
    "sheet[f'C1'] = \"Year\"\n",
    "sheet[f'D1'] = \"Companie name\"\n",
    "sheet[f'E1'] = \"Industry\"\n",
    "sheet[f'F1'] = \"Income\"\n",
    "sheet[f'G1'] = \"Profit\"\n",
    "sheet[f'H1'] = 'Currensy'\n",
    "sheet[f'I1'] = \"Staff\"\n",
    "sheet[f'J1'] = 'Assets'\n",
    "sheet[f'K1'] = 'Equity'\n",
    "sheet[f'L1'] = 'ROA'\n",
    "sheet[f'M1'] = 'Net Profit coef'\n",
    "sheet[f'N1'] = \"Site\"\n",
    "sheet[f'O1'] = \"Link\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\n中国石油化工股份有限公司\\nChina Petroleum & Chemical Corporation\\n', '2,360,193', '51,119', '百万元', '中国', '石油、天然气、石化', '北京市', '446225', '1,595,504', '727,244', '2.2', '7', 'http://www.sinopec.com')\n"
     ]
    }
   ],
   "source": [
    "print(get_company_info('https://www.caifuzhongwen.com/fortune500/gongsi/china500/2018/1.htm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_company_info(link):\n",
    "    companies = []\n",
    "    comp_page = requests.get(link).content\n",
    "\n",
    "    soup_c = BeautifulSoup(comp_page, 'html.parser')\n",
    "\n",
    "    row_1 = soup_c.find('div', class_ = 'company-row1')\n",
    "    comp_name = row_1.find('div', class_= 'txt').get_text()\n",
    "    currensy = row_1.find('div', class_= 'box2').find_all('div', class_ = 'tit')[0].get_text().split('（')[-1][:-1:]\n",
    "    income = row_1.find('div', class_= 'box2').find_all('div', class_ = 'price')[0].get_text()\n",
    "    profit = row_1.find('div', class_= 'box2').find_all('div', class_ = 'price')[1].get_text()\n",
    "\n",
    "    row_2 = soup_c.find('div', class_ = 'company-row2').find_all('div', class_ = 'con')\n",
    "    country = row_2[1].get_text()\n",
    "    industry = row_2[2].get_text()\n",
    "    city = row_2[3].get_text()\n",
    "    staff = row_2[4].get_text()\n",
    "    site = row_2[5].find('a').get('href')\n",
    "\n",
    "    row_3 = soup_c.find('div', class_ = 'company-row3').find('div', class_ = 'table-detail').find_all('tr')\n",
    "    assets = row_3[3].find_all('td')[1].get_text().strip()\n",
    "    equity = row_3[4].find_all('td')[1].get_text().strip()\n",
    "    roa = row_3[6].find_all('td')[1].get_text().strip()\n",
    "    profit_coef = row_3[7].find_all('td')[1].get_text().strip()\n",
    "    \n",
    "    \n",
    "    return comp_name, income, profit, currensy, country, industry, city, staff, assets, equity, roa, profit_coef, site\n",
    "    #companies.append((comp_name, site))\n",
    "    \n",
    "#     sheet[f'A{ind+2}'] = country\n",
    "#     sheet[f'B{ind+2}'] = city\n",
    "#     sheet[f'C{ind+2}'] = comp_name\n",
    "#     sheet[f'D{ind+2}'] = industry\n",
    "#     sheet[f'E{ind+2}'] = income\n",
    "#     sheet[f'F{ind+2}'] = profit\n",
    "#     sheet[f'G{ind+2}'] = staff\n",
    "#     sheet[f'H{ind+2}'] = site\n",
    "    \n",
    "\n",
    "\n",
    "# workbook.save('BT_companies.xlsx')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_excel(ind, comp_name, year, income, profit, currensy, country, industry, city, staff, assets, equity, roa, profit_coef, site, link):\n",
    "    sheet[f'A{ind}'] = country\n",
    "    sheet[f'B{ind}'] = city\n",
    "    sheet[f'C{ind}'] = year\n",
    "    sheet[f'D{ind}'] = comp_name\n",
    "    sheet[f'E{ind}'] = industry\n",
    "    sheet[f'F{ind}'] = income\n",
    "    sheet[f'G{ind}'] = profit\n",
    "    sheet[f'H{ind}'] = currensy\n",
    "    sheet[f'I{ind}'] = staff\n",
    "    sheet[f'J{ind}'] = assets\n",
    "    sheet[f'K{ind}'] = equity\n",
    "    sheet[f'L{ind}'] = roa\n",
    "    sheet[f'M{ind}'] = profit_coef\n",
    "    sheet[f'N{ind}'] = site\n",
    "    sheet[f'O{ind}'] = link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2\n",
    "for y in range(7):\n",
    "    \n",
    "    url_fortune = f\"https://www.caifuzhongwen.com/fortune500/paiming/china500/{2018 + y}_%e4%b8%ad%e5%9b%bd500%e5%bc%ba.htm\"\n",
    "    url_base = f\"https://www.caifuzhongwen.com/fortune500/gongsi/china500/{2018 + y}/\"\n",
    "    # Making a GET request\n",
    "    r = requests.get(url_fortune)\n",
    "\n",
    "    # Parsing the HTML\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    #print(soup.prettify())\n",
    "\n",
    "    g_table = soup.find('div', class_ = 'g-table table-ranking')\n",
    "    companies = g_table.find('tbody').find_all('tr')\n",
    "\n",
    "    links = []\n",
    "    year = y + 2018\n",
    "\n",
    "    for tr in companies:\n",
    "        companie_code = tr.find('a').get('href').split('/')[-1]\n",
    "        link = url_base + companie_code\n",
    "#         links.append(link)\n",
    "        comp_name, income, profit, currensy, country, industry, city, staff, assets, equity, roa, profit_coef, site = get_company_info(link)\n",
    "        save_as_excel(k, comp_name, year, income, profit, currensy, country, industry, city, staff, assets, equity, roa, profit_coef, site, link)\n",
    "        k+=1\n",
    "    #print(g_table.find('tbody').find_all('tr'))\n",
    "\n",
    "workbook.save('companies_PD_0504.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781,126.2 1.7 2.7\n"
     ]
    }
   ],
   "source": [
    "get_company_info('https://www.caifuzhongwen.com/fortune500/gongsi/china500/2024/1475.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook.save('BT_companies.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
